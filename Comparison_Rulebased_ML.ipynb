{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "c77aQASHrZun",
        "0EsXU0fuxni4",
        "bk-rr0Y8v_3J"
      ],
      "authorship_tag": "ABX9TyMi865m7bNUNOjzLnWYmKnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiepat/Google-Colab/blob/main/Comparison_Rulebased_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NSL-KDD Datensatz einlesen und vorbereiten"
      ],
      "metadata": {
        "id": "hNu-cUqgj1kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schritt 1: Google Colab vorbereiten, Datensatz laden und vorbereiten"
      ],
      "metadata": {
        "id": "Zuc83_ULC0kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH21AHkrWmRB",
        "outputId": "fdbb5327-db73-455b-9b41-46207075fdea",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ace_tools in /usr/local/lib/python3.11/dist-packages (0.0)\n",
            "✅ NSL-KDD Datensätze erfolgreich eingelesen und verarbeitet!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              " 0         0        491          0     0               0       0    0   \n",
              " 1         0        146          0     0               0       0    0   \n",
              " 2         0          0          0     0               0       0    0   \n",
              " 3         0        232       8153     0               0       0    0   \n",
              " 4         0        199        420     0               0       0    0   \n",
              " \n",
              "    num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
              " 0                  0          0                0  ...         0          0   \n",
              " 1                  0          0                0  ...         0          0   \n",
              " 2                  0          0                0  ...         0          0   \n",
              " 3                  0          1                0  ...         0          0   \n",
              " 4                  0          1                0  ...         0          0   \n",
              " \n",
              "    flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
              " 0            0          0        0        0        0        0        1   \n",
              " 1            0          0        0        0        0        0        1   \n",
              " 2            0          0        1        0        0        0        0   \n",
              " 3            0          0        0        0        0        0        1   \n",
              " 4            0          0        0        0        0        0        1   \n",
              " \n",
              "    flag_SH  \n",
              " 0        0  \n",
              " 1        0  \n",
              " 2        0  \n",
              " 3        0  \n",
              " 4        0  \n",
              " \n",
              " [5 rows x 123 columns],\n",
              "    duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
              " 0         0          0          0     0               0       0    0   \n",
              " 1         0          0          0     0               0       0    0   \n",
              " 2         2      12983          0     0               0       0    0   \n",
              " 3         0         20          0     0               0       0    0   \n",
              " 4         1          0         15     0               0       0    0   \n",
              " \n",
              "    num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
              " 0                  0          0                0  ...         1          0   \n",
              " 1                  0          0                0  ...         1          0   \n",
              " 2                  0          0                0  ...         0          0   \n",
              " 3                  0          0                0  ...         0          0   \n",
              " 4                  0          0                0  ...         0          1   \n",
              " \n",
              "    flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
              " 0            0          0        0        0        0        0        0   \n",
              " 1            0          0        0        0        0        0        0   \n",
              " 2            0          0        0        0        0        0        1   \n",
              " 3            0          0        0        0        0        0        1   \n",
              " 4            0          0        0        0        0        0        0   \n",
              " \n",
              "    flag_SH  \n",
              " 0        0  \n",
              " 1        0  \n",
              " 2        0  \n",
              " 3        0  \n",
              " 4        0  \n",
              " \n",
              " [5 rows x 123 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "NSL-KDD Datensatz einlesen, Regelbasiertes System und ML-Vergleich mit mehreren Algorithmen\n",
        "\"\"\"\n",
        "# 📌 1. Bibliotheken importieren\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# 📌 2. Spaltenbezeichnungen gemäß NSL-KDD Dokumentation\n",
        "dataset_columns = [\n",
        "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
        "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\",\n",
        "    \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\",\n",
        "    \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
        "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
        "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\",\n",
        "    \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
        "    \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
        "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
        "    \"dst_host_srv_rerror_rate\", \"label\", \"difficulty_level\"\n",
        "]\n",
        "\n",
        "# 📌 3. URLs für Trainings- und Testdatensätze\n",
        "train_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt\"\n",
        "\n",
        "# 📌 4. Datensätze einlesen\n",
        "df_train = pd.read_csv(train_url, names=dataset_columns, header=None)\n",
        "df_test = pd.read_csv(test_url, names=dataset_columns, header=None)\n",
        "\n",
        "# 📌 5. Entfernen der \"difficulty_level\" Spalte, da sie für das Training irrelevant ist\n",
        "df_train.drop(columns=[\"difficulty_level\"], inplace=True)\n",
        "df_test.drop(columns=[\"difficulty_level\"], inplace=True)\n",
        "\n",
        "# 📌 6. Labels in binäre Werte umwandeln (0 = normal, 1 = Angriff)\n",
        "df_train[\"label\"] = df_train[\"label\"].apply(lambda x: 0 if x == \"normal\" else 1)\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(lambda x: 0 if x == \"normal\" else 1)\n",
        "\n",
        "# 📌 7. One-Hot-Encoding für kategoriale Features\n",
        "categorical_columns = [\"protocol_type\", \"service\", \"flag\"]\n",
        "df_train = pd.get_dummies(df_train, columns=categorical_columns, dtype=int)\n",
        "df_test = pd.get_dummies(df_test, columns=categorical_columns, dtype=int)\n",
        "\n",
        "# 📌 8. Sicherstellen, dass beide Datensätze dieselben Spalten haben\n",
        "df_train, df_test = df_train.align(df_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# 📌 9. Spalte label aus Train- und Testdaten entfernen.\n",
        "X_train = df_train.drop(columns=[\"label\"])\n",
        "y_train = df_train[\"label\"]\n",
        "\n",
        "X_test = df_test.drop(columns=[\"label\"])\n",
        "y_test = df_test[\"label\"]\n",
        "\n",
        "print(\"✅ NSL-KDD Datensätze erfolgreich eingelesen und verarbeitet!\")\n",
        "\n",
        "# 📌 9. Ausgabe der ersten 5 Zeilen\n",
        "df_train.head(), df_test.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regelbasiertes System"
      ],
      "metadata": {
        "id": "GHkb0Vm3kEx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schritt 2: Regelbasiertes System"
      ],
      "metadata": {
        "id": "0_cbBpHiDho2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. Regelbasierte Priorisierung von Sicherheitsvorfällen\n",
        "def map_priority(row):\n",
        "    \"\"\"Simulierte regelbasierte Priorisierung\"\"\"\n",
        "    if row[\"serror_rate\"] > 0.5 or row[\"srv_serror_rate\"] > 0.5:\n",
        "        return 1  # Kritisch\n",
        "    elif row[\"rerror_rate\"] > 0.3 or row[\"srv_rerror_rate\"] > 0.3:\n",
        "        return 2  # Hoch\n",
        "    elif row[\"count\"] > 50:\n",
        "        return 3  # Mittel\n",
        "    else:\n",
        "        return 4  # Gering\n",
        "\n",
        "# 📌 2. Anwenden der Priorisierungsfunktion\n",
        "df_test[\"rule_priority\"] = df_test.apply(map_priority, axis=1)\n",
        "\n",
        "# 📌 3. Regelbasierte Priorität in binäre Werte umwandeln (1-2 = Angriff, 3-4 = normal)\n",
        "df_test[\"rule_priority_binary\"] = np.where(df_test[\"rule_priority\"] <= 2, 1, 0)\n",
        "\n",
        "rule_precision = precision_score(y_test, df_test[\"rule_priority_binary\"], zero_division=1)\n",
        "rule_recall = recall_score(y_test, df_test[\"rule_priority_binary\"])\n",
        "\n",
        "# 📌 4. Zusätzliche Metriken berechnen\n",
        "rule_f1 = f1_score(y_test, df_test[\"rule_priority_binary\"])\n",
        "rule_accuracy = accuracy_score(y_test, df_test[\"rule_priority_binary\"])\n",
        "rule_roc_auc = roc_auc_score(y_test, df_test[\"rule_priority_binary\"])\n",
        "\n",
        "# 📌 5. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, df_test[\"rule_priority_binary\"]).ravel()\n",
        "rule_fpr = fp / (fp + tn)\n",
        "rule_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 6. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "rule_p_at_100 = precision_at_k(y_test.to_numpy(), df_test[\"rule_priority_binary\"].to_numpy(), k=100)\n",
        "\n",
        "# 📌 7. Ergebnisse ausgeben\n",
        "print(f\"✅ Regelbasiert: Precision = {rule_precision:.2f}, Recall = {rule_recall:.2f}\")\n",
        "print(f\"✅ Regelbasiert: F1-Score = {rule_f1:.2f}, Accuracy = {rule_accuracy:.2f}\")\n",
        "print(f\"✅ Regelbasiert: ROC-AUC = {rule_roc_auc:.2f}\")\n",
        "print(f\"✅ Regelbasiert: False Positive Rate (FPR) = {rule_fpr:.2f}\")\n",
        "print(f\"✅ Regelbasiert: False Negative Rate (FNR) = {rule_fnr:.2f}\")\n",
        "print(f\"✅ Regelbasiert: Precision@100 = {rule_p_at_100:.2f}\")\n"
      ],
      "metadata": {
        "id": "UlyDE2QbEJEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8ea486-5085-43a1-c72f-21b4dfe73001",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Regelbasiert: Precision = 0.99, Recall = 0.60\n",
            "✅ Regelbasiert: F1-Score = 0.75, Accuracy = 0.77\n",
            "✅ Regelbasiert: ROC-AUC = 0.80\n",
            "✅ Regelbasiert: False Positive Rate (FPR) = 0.01\n",
            "✅ Regelbasiert: False Negative Rate (FNR) = 0.40\n",
            "✅ Regelbasiert: Precision@100 = 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest (ohne Tuning)"
      ],
      "metadata": {
        "id": "cPO8hJqylgOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest trainieren und gegen Testdaten laufen lassen. Es wurde noch kein Feature Engineering, Feature Transformation, Feature Selection oder Hyperparameter-Tuning vorgenommen."
      ],
      "metadata": {
        "id": "nubjKXbjEppE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. Machine Learning Modell (Random Forest)\n",
        "\n",
        "# Die Spalten label, rule_priority and rule_priority_binary aus dem Test-\n",
        "# datensatz entfernen.\n",
        "X_test = df_test.drop(columns=[\"label\", \"rule_priority\", \"rule_priority_binary\"])\n",
        "y_test = df_test[\"label\"]\n",
        "\n",
        "# 📌 2. Modell trainieren\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 📌 3. Vorhersage auf Testdaten\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# 📌 4. Performance-Metriken berechnen\n",
        "rf_precision = precision_score(y_test, rf_predictions, zero_division=1)\n",
        "rf_recall = recall_score(y_test, rf_predictions)\n",
        "\n",
        "# 📌 5. Zusätzliche Metriken berechnen\n",
        "rf_f1 = f1_score(y_test, rf_predictions)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "rf_roc_auc = roc_auc_score(y_test, rf_predictions)\n",
        "\n",
        "# 📌 6. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, rf_predictions).ravel()\n",
        "rf_fpr = fp / (fp + tn)\n",
        "rf_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 7. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "rf_p_at_100 = precision_at_k(y_test.to_numpy(), rf_predictions, k=100)\n",
        "\n",
        "# 📌 8. Ergebnisse ausgeben\n",
        "print(f\"✅ Random Forest: Precision = {rf_precision:.2f}, Recall = {rf_recall:.2f}\")\n",
        "print(f\"✅ Random Forest: F1-Score = {rf_f1:.2f}, Accuracy = {rf_accuracy:.2f}\")\n",
        "print(f\"✅ Random Forest: ROC-AUC = {rf_roc_auc:.2f}\")\n",
        "print(f\"✅ Random Forest: False Positive Rate (FPR) = {rf_fpr:.2f}\")\n",
        "print(f\"✅ Random Forest: False Negative Rate (FNR) = {rf_fnr:.2f}\")\n",
        "print(f\"✅ Random Forest: Precision@100 = {rf_p_at_100:.2f}\")"
      ],
      "metadata": {
        "id": "vZ7wNE3KEynq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e863b66-97f6-450d-b285-16d74c5f9470",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random Forest: Precision = 0.97, Recall = 0.61\n",
            "✅ Random Forest: F1-Score = 0.75, Accuracy = 0.77\n",
            "✅ Random Forest: ROC-AUC = 0.79\n",
            "✅ Random Forest: False Positive Rate (FPR) = 0.03\n",
            "✅ Random Forest: False Negative Rate (FNR) = 0.39\n",
            "✅ Random Forest: Precision@100 = 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weitere ML-Modelle (ohne Tuning)"
      ],
      "metadata": {
        "id": "YbKHY65yvQJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: XGBoost"
      ],
      "metadata": {
        "id": "CIzYMn5ovT_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. ML-Modell: XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 📌 2. XGBoost-Modell mit optimierten Einstellungen\n",
        "xgb_model = XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1,\n",
        "                          scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1),\n",
        "                          eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "print(\"🔍 Training XGBoost...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 📌 3. Vorhersage mit XGBoost\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# 📌 4. Performance-Metriken für XGBoost berechnen\n",
        "xgb_precision = precision_score(y_test, xgb_predictions, zero_division=1)\n",
        "xgb_recall = recall_score(y_test, xgb_predictions)\n",
        "\n",
        "# 📌 5. Zusätzliche Metriken berechnen\n",
        "xgb_f1 = f1_score(y_test, xgb_predictions)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "xgb_roc_auc = roc_auc_score(y_test, xgb_predictions)\n",
        "\n",
        "# 📌 6. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, xgb_predictions).ravel()\n",
        "xgb_fpr = fp / (fp + tn)\n",
        "xgb_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 7. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "xgb_p_at_100 = precision_at_k(y_test.to_numpy(), xgb_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ XGBoost: Precision = {xgb_precision:.2f}, Recall = {xgb_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03MtQC2XO6NH",
        "outputId": "217abaa2-d7f5-4a57-f7ea-764d511e5614",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Training XGBoost...\n",
            "✅ XGBoost: Precision = 0.97, Recall = 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: LightGBM"
      ],
      "metadata": {
        "id": "9Am4xGDQvb-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. ML-Modell: LightGBM\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "# 📌 2. LightGBM Modell\n",
        "lgbm_model = LGBMClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, random_state=42)\n",
        "print(\"🔍 Training LightGBM...\")\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "lgbm_predictions = lgbm_model.predict(X_test)\n",
        "\n",
        "# 📌 3. Performance-Metriken berechnen\n",
        "lgbm_precision = precision_score(y_test, lgbm_predictions, zero_division=1)\n",
        "lgbm_recall = recall_score(y_test, lgbm_predictions)\n",
        "\n",
        "# 📌 4. Zusätzliche Metriken berechnen\n",
        "lgbm_f1 = f1_score(y_test, lgbm_predictions)\n",
        "lgbm_accuracy = accuracy_score(y_test, lgbm_predictions)\n",
        "lgbm_roc_auc = roc_auc_score(y_test, lgbm_predictions)\n",
        "\n",
        "# 📌 5. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, lgbm_predictions).ravel()\n",
        "lgbm_fpr = fp / (fp + tn)\n",
        "lgbm_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 6. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "lgbm_p_at_100 = precision_at_k(y_test.to_numpy(), lgbm_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ LightGBM: Precision = {lgbm_precision:.2f}, Recall = {lgbm_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnUCJioZicLV",
        "outputId": "019ca777-f4aa-4ca6-f9f2-56742c73ea18",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Training LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 58630, number of negative: 67343\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024365 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3296\n",
            "[LightGBM] [Info] Number of data points in the train set: 125973, number of used features: 110\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465417 -> initscore=-0.138552\n",
            "[LightGBM] [Info] Start training from score -0.138552\n",
            "✅ LightGBM: Precision = 0.97, Recall = 0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: CatBoost"
      ],
      "metadata": {
        "id": "xYcJluZNvgE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. ML-Modell: CatBoost\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 📌 2. CatBoost Modell\n",
        "catboost_model = CatBoostClassifier(n_estimators=200, depth=10, learning_rate=0.1, verbose=0, random_state=42)\n",
        "print(\"🔍 Training CatBoost...\")\n",
        "catboost_model.fit(X_train, y_train)\n",
        "catboost_predictions = catboost_model.predict(X_test)\n",
        "\n",
        "# 📌 3. Performance-Metriken berechnen\n",
        "catboost_precision = precision_score(y_test, catboost_predictions, zero_division=1)\n",
        "catboost_recall = recall_score(y_test, catboost_predictions)\n",
        "\n",
        "# 📌 4. Zusätzliche Metriken berechnen\n",
        "catboost_f1 = f1_score(y_test, catboost_predictions)\n",
        "catboost_accuracy = accuracy_score(y_test, catboost_predictions)\n",
        "catboost_roc_auc = roc_auc_score(y_test, catboost_predictions)\n",
        "\n",
        "# 📌 5. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, catboost_predictions).ravel()\n",
        "catboost_fpr = fp / (fp + tn)\n",
        "catboost_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 6. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "catboost_p_at_100 = precision_at_k(y_test.to_numpy(), catboost_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ CatBoost: Precision = {catboost_precision:.2f}, Recall = {catboost_recall:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "RN8UJnULvlvC",
        "outputId": "a53460d5-a2b9-4730-d04b-a23dff228cfd",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "🔍 Training CatBoost...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-55b742c6a576>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcatboost_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔍 Training CatBoost...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcatboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcatboost_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: Isolation Forest"
      ],
      "metadata": {
        "id": "8Ruu0Bs50Pe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. ML-Modell: Isolation Forest\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# 📌 2. Isolation Forest Modell trainieren\n",
        "iso_forest = IsolationForest(n_estimators=100, contamination=0.15, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "\n",
        "# 📌 3. Anomalien im Testset erkennen (Anomalie = -1, Normal = 1)\n",
        "iso_predictions = iso_forest.predict(X_test)\n",
        "iso_predictions = np.where(iso_predictions == -1, 1, 0)  # Umwandeln in 1 (Angriff) oder 0 (Normal)\n",
        "\n",
        "# 📌 4. Performance-Metriken für Isolation Forest berechnen\n",
        "iso_precision = precision_score(y_test, iso_predictions, zero_division=1)\n",
        "iso_recall = recall_score(y_test, iso_predictions)\n",
        "\n",
        "# 📌 5. Zusätzliche Metriken berechnen\n",
        "iso_f1 = f1_score(y_test, iso_predictions)\n",
        "iso_accuracy = accuracy_score(y_test, iso_predictions)\n",
        "iso_roc_auc = roc_auc_score(y_test, iso_predictions)\n",
        "\n",
        "# 📌 6. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, iso_predictions).ravel()\n",
        "iso_fpr = fp / (fp + tn)\n",
        "iso_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 7. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "iso_p_at_100 = precision_at_k(y_test.to_numpy(), iso_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ Isolation Forest: Precision = {iso_precision:.2f}, Recall = {iso_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUWSOXYXPpBd",
        "outputId": "a4d0b841-2eae-47c9-d327-9d50c850ffa6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Isolation Forest: Precision = 0.86, Recall = 0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: One-Class SVM"
      ],
      "metadata": {
        "id": "MVMlx0RK0aRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 📌 1. Feature Selection: Wähle nur die wichtigsten Features\n",
        "selected_features = X_train.columns[:20]  # Nutze die ersten 20 Features (kann angepasst werden)\n",
        "X_train_reduced = X_train[selected_features]\n",
        "X_test_reduced = X_test[selected_features]\n",
        "\n",
        "# 📌 2. Standardisierung (Wichtig für SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
        "X_test_scaled = scaler.transform(X_test_reduced)\n",
        "\n",
        "# 📌 3. Trainingsdaten reduzieren, um Geschwindigkeit zu erhöhen\n",
        "X_train_sampled = X_train_scaled[:len(X_train_scaled) // 2]  # Nutze nur 50% der Daten\n",
        "\n",
        "# 📌 4. One-Class SVM trainieren (mit optimierten Parametern)\n",
        "ocsvm = OneClassSVM(kernel=\"rbf\", gamma=\"scale\", nu=0.1)\n",
        "print(\"🔍 One-Class SVM Training gestartet...\")\n",
        "ocsvm.fit(X_train_sampled)  # Trainiere nur auf den reduzierten Daten\n",
        "print(\"✅ One-Class SVM Training abgeschlossen!\")\n",
        "\n",
        "# 📌 5. Vorhersage auf Testdaten (-1 = Anomalie, 1 = Normal)\n",
        "ocsvm_predictions = ocsvm.predict(X_test_scaled)\n",
        "ocsvm_predictions = np.where(ocsvm_predictions == -1, 1, 0)  # Umwandeln in 1 (Angriff) oder 0 (Normal)\n",
        "\n",
        "# 📌 6. Performance-Metriken für One-Class SVM berechnen\n",
        "ocsvm_precision = precision_score(y_test, ocsvm_predictions, zero_division=1)\n",
        "ocsvm_recall = recall_score(y_test, ocsvm_predictions)\n",
        "\n",
        "# 📌 7. Zusätzliche Metriken berechnen\n",
        "ocsvm_f1 = f1_score(y_test, ocsvm_predictions)\n",
        "ocsvm_accuracy = accuracy_score(y_test, ocsvm_predictions)\n",
        "ocsvm_roc_auc = roc_auc_score(y_test, ocsvm_predictions)\n",
        "\n",
        "# 📌 8. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, ocsvm_predictions).ravel()\n",
        "ocsvm_fpr = fp / (fp + tn)\n",
        "ocsvm_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 9. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "ocsvm_p_at_100 = precision_at_k(y_test.to_numpy(), ocsvm_predictions, k=100)\n",
        "\n",
        "print(f\"✅ One-Class SVM (Optimiert): Precision = {ocsvm_precision:.2f}, Recall = {ocsvm_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVt4UEdwQ8dT",
        "outputId": "e97d8753-48c5-4579-ea3a-b516c1de4b71",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 One-Class SVM Training gestartet...\n",
            "✅ One-Class SVM Training abgeschlossen!\n",
            "✅ One-Class SVM (Optimiert): Precision = 0.81, Recall = 0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML-Modell: AutoEncoder"
      ],
      "metadata": {
        "id": "hZ2tiBCB00mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1.  ML-Modell: Autoencoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 📌 2. GPU-Check\n",
        "print(\"🔍 Verfügbare GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# 📌 3. Feature Scaling (Min-Max Normalisierung für 0-1 Werte)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.iloc[:, :20])  # Nur Top-20 Features\n",
        "X_test_scaled = scaler.transform(X_test.iloc[:, :20])\n",
        "\n",
        "# 📌 4. Autoencoder-Modell definieren\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "autoencoder = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation=\"relu\", input_shape=(input_dim,)),  # Weniger Neuronen für Effizienz\n",
        "    keras.layers.Dense(8, activation=\"relu\"),\n",
        "    keras.layers.Dense(16, activation=\"relu\"),\n",
        "    keras.layers.Dense(input_dim, activation=\"sigmoid\")  # Output entspricht Input-Dimension\n",
        "])\n",
        "\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# 📌 5. Training des Autoencoders\n",
        "print(\"🔍 Starte Autoencoder-Training...\")\n",
        "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=15, batch_size=128, shuffle=True, verbose=1)\n",
        "\n",
        "# 📌 6. Fehler berechnen (je höher, desto wahrscheinlicher Anomalie)\n",
        "reconstruction = autoencoder.predict(X_test_scaled)\n",
        "mse = np.mean(np.power(X_test_scaled - reconstruction, 2), axis=1)\n",
        "\n",
        "# 📌 7. Schwellenwert für Anomalien festlegen (90. Perzentil)\n",
        "threshold = np.percentile(mse, 90)\n",
        "autoencoder_predictions = (mse > threshold).astype(int)  # 1 = Angriff, 0 = Normal\n",
        "\n",
        "# 📌 8. Performance-Metriken für Autoencoder berechnen\n",
        "autoencoder_precision = precision_score(y_test, autoencoder_predictions, zero_division=1)\n",
        "autoencoder_recall = recall_score(y_test, autoencoder_predictions)\n",
        "\n",
        "# 📌 9. Zusätzliche Metriken berechnen\n",
        "autoencoder_f1 = f1_score(y_test, autoencoder_predictions)\n",
        "autoencoder_accuracy = accuracy_score(y_test, autoencoder_predictions)\n",
        "autoencoder_roc_auc = roc_auc_score(y_test, autoencoder_predictions)\n",
        "\n",
        "# 📌 10. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, autoencoder_predictions).ravel()\n",
        "autoencoder_fpr = fp / (fp + tn)\n",
        "autoencoder_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 11. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "def precision_at_k(y_true, y_pred, k=100):\n",
        "    \"\"\"Berechnet Precision@K für Priorisierungssysteme\"\"\"\n",
        "    top_k = np.argsort(y_pred)[-k:]  # Nimmt die K höchsten Werte\n",
        "    relevant = sum(y_true[top_k])  # Wie viele echte Incidents sind unter den Top-K?\n",
        "    return relevant / k  # Precision@K\n",
        "\n",
        "autoencoder_p_at_100 = precision_at_k(y_test.to_numpy(), autoencoder_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ Autoencoder: Precision = {autoencoder_precision:.2f}, Recall = {autoencoder_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S75eNpWITTId",
        "outputId": "79116fb8-69a3-4ccb-8af3-4c4a332d25a0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Verfügbare GPUs: []\n",
            "🔍 Starte Autoencoder-Training...\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0772\n",
            "Epoch 2/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012\n",
            "Epoch 3/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.7332e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.5384e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.4447e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7869e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.4970e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8314e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.5606e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.2862e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7117e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.9371e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6907e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.5168e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m985/985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.8957e-04\n",
            "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "✅ Autoencoder: Precision = 0.65, Recall = 0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybride Modelle"
      ],
      "metadata": {
        "id": "O6jVvnnu1VLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regelbasiert & Random Forest"
      ],
      "metadata": {
        "id": "67oDnCHC1Z-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. Hybrid-Modell: Kombination aus Regelbasiert & Random Forest\n",
        "hybrid_rrf_predictions = df_test[\"rule_priority_binary\"].copy()  # Starte mit regelbasierter Vorhersage\n",
        "\n",
        "# 📌 2. Random Forest nur auf ungelabelte Fälle anwenden (wenn Regelbasiert = 0)\n",
        "indices_ml_needed = df_test[df_test[\"rule_priority_binary\"] == 0].index  # Wo Regelbasierte Methode unsicher ist\n",
        "\n",
        "# 📌 3. RF-Vorhersagen für diese Fälle generieren\n",
        "ml_predictions = rf_model.predict(X_test.loc[indices_ml_needed])\n",
        "\n",
        "# 📌 4. Ersetze die Werte im Hybrid-Array nur dort, wo ML nötig ist\n",
        "hybrid_rrf_predictions.loc[indices_ml_needed] = ml_predictions\n",
        "\n",
        "# 📌 5. Performance-Metriken berechnen\n",
        "hybrid_rrf_precision = precision_score(y_test, hybrid_rrf_predictions, zero_division=1)\n",
        "hybrid_rrf_recall = recall_score(y_test, hybrid_rrf_predictions)\n",
        "hybrid_rrf_f1 = f1_score(y_test, hybrid_rrf_predictions)\n",
        "hybrid_rrf_accuracy = accuracy_score(y_test, hybrid_rrf_predictions)\n",
        "hybrid_rrf_roc_auc = roc_auc_score(y_test, hybrid_rrf_predictions)\n",
        "\n",
        "# 📌 6. False Positive Rate (FPR) & False Negative Rate (FNR) berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, hybrid_rrf_predictions).ravel()\n",
        "hybrid_rrf_fpr = fp / (fp + tn)\n",
        "hybrid_rrf_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 7. Precision@100 berechnen (Wichtig für SOC-Priorisierung!)\n",
        "hybrid_rrf_p_at_100 = precision_at_k(y_test.to_numpy(), hybrid_rrf_predictions.to_numpy(), k=100)\n",
        "\n",
        "# 📌 8. Ergebnisse ausgeben\n",
        "print(f\"✅ Hybrid (Regel + RF): Precision = {hybrid_rrf_precision:.2f}, Recall = {hybrid_rrf_recall:.2f}\")\n",
        "print(f\"✅ Hybrid (Regel + RF): F1-Score = {hybrid_rrf_f1:.2f}, Accuracy = {hybrid_rrf_accuracy:.2f}\")\n",
        "print(f\"✅ Hybrid (Regel + RF): ROC-AUC = {hybrid_rrf_roc_auc:.2f}\")\n",
        "print(f\"✅ Hybrid (Regel + RF): False Positive Rate (FPR) = {hybrid_rrf_fpr:.2f}\")\n",
        "print(f\"✅ Hybrid (Regel + RF): False Negative Rate (FNR) = {hybrid_rrf_fnr:.2f}\")\n",
        "print(f\"✅ Hybrid (Regel + RF): Precision@100 = {hybrid_rrf_p_at_100:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxxvW78389x",
        "outputId": "c490ce3e-d56e-4e0b-9e83-bbe4b60e7f34",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid (Regel + RF): Precision = 0.97, Recall = 0.74\n",
            "✅ Hybrid (Regel + RF): F1-Score = 0.84, Accuracy = 0.84\n",
            "✅ Hybrid (Regel + RF): ROC-AUC = 0.85\n",
            "✅ Hybrid (Regel + RF): False Positive Rate (FPR) = 0.03\n",
            "✅ Hybrid (Regel + RF): False Negative Rate (FNR) = 0.26\n",
            "✅ Hybrid (Regel + RF): Precision@100 = 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost & Isolation Forest"
      ],
      "metadata": {
        "id": "J_yEb1ZB1fbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 1. Hybrides Modell: Kombination aus XGBoost & Isolation Forest\n",
        "hybrid_xgbif_predictions = np.logical_or(xgb_predictions, iso_predictions).astype(int)\n",
        "\n",
        "# 📌 2. Performance-Metriken berechnen\n",
        "hybrid_xgbif_precision = precision_score(y_test, hybrid_xgbif_predictions, zero_division=1)\n",
        "hybrid_xgbif_recall = recall_score(y_test, hybrid_xgbif_predictions)\n",
        "hybrid_xgbif_f1 = f1_score(y_test, hybrid_xgbif_predictions)\n",
        "hybrid_xgbif_accuracy = accuracy_score(y_test, hybrid_xgbif_predictions)\n",
        "hybrid_xgbif_roc_auc = roc_auc_score(y_test, hybrid_xgbif_predictions)\n",
        "\n",
        "# 📌 3. False Positive & False Negative Rate berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, hybrid_xgbif_predictions).ravel()\n",
        "hybrid_xgbif_fpr = fp / (fp + tn)\n",
        "hybrid_xgbif_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 4. Precision@100 berechnen\n",
        "hybrid_xgbif_p_at_100 = precision_at_k(y_test.to_numpy(), hybrid_xgbif_predictions, k=100)\n",
        "\n",
        "\n",
        "print(f\"✅ Hybrid (XGBoost + Isolation Forest): Precision = {hybrid_xgbif_precision:.2f}, Recall = {hybrid_xgbif_recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyvp8L60QGtn",
        "outputId": "ab9f1872-1055-423f-f96d-6588d95cef22",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid (XGBoost + Isolation Forest): Precision = 0.93, Recall = 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM & One-Class SVM\n",
        "\n"
      ],
      "metadata": {
        "id": "Aztn37i06YWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 📌 1. Feature Selection für schnelles Training\n",
        "selected_features = X_train.columns[:20]  # Nutze nur die Top 20 Features\n",
        "X_train_reduced = X_train[selected_features]\n",
        "X_test_reduced = X_test[selected_features]\n",
        "\n",
        "# 📌 2. Standardisierung (wichtig für One-Class SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
        "X_test_scaled = scaler.transform(X_test_reduced)\n",
        "\n",
        "# 📌 3. One-Class SVM trainieren (nur auf normalem Traffic)\n",
        "X_train_sampled = X_train_scaled[:len(X_train_scaled) // 2]  # Nutze nur 50 % für schnelleres Training\n",
        "ocsvm = OneClassSVM(kernel=\"rbf\", gamma=\"scale\", nu=0.1)\n",
        "print(\"🔍 Training One-Class SVM...\")\n",
        "ocsvm.fit(X_train_sampled)\n",
        "print(\"✅ One-Class SVM Training abgeschlossen!\")\n",
        "\n",
        "# 📌 4. Vorhersage mit One-Class SVM (-1 = Anomalie, 1 = Normal)\n",
        "ocsvm_predictions = ocsvm.predict(X_test_scaled)\n",
        "ocsvm_predictions = np.where(ocsvm_predictions == -1, 1, 0)  # Anomalien als Angriff markieren\n",
        "\n",
        "# 📌 5. LightGBM trainieren\n",
        "lgbm_model = LGBMClassifier(n_estimators=200, max_depth=10, learning_rate=0.1, random_state=42)\n",
        "print(\"🔍 Training LightGBM...\")\n",
        "lgbm_model.fit(X_train_reduced, y_train)\n",
        "lgbm_predictions = lgbm_model.predict(X_test_reduced)\n",
        "print(\"✅ LightGBM Training abgeschlossen!\")\n",
        "\n",
        "# 📌 6. Hybrid-Entscheidung: Falls One-Class SVM Angriff erkennt, setze 1, sonst nutze LightGBM\n",
        "hybrid_lgbmsvm_predictions = ocsvm_predictions.copy()\n",
        "indices_ml_needed = np.where(ocsvm_predictions == 0)[0]  # Wo OCSVM normal meldet → LGBM entscheidet\n",
        "\n",
        "# 📌 7. LGBM-Vorhersagen nur für unklare Fälle übernehmen\n",
        "hybrid_lgbmsvm_predictions[indices_ml_needed] = lgbm_predictions[indices_ml_needed]\n",
        "\n",
        "# 📌 8. Performance-Metriken berechnen\n",
        "hybrid_lgbmsvm_precision = precision_score(y_test, hybrid_lgbmsvm_predictions, zero_division=1)\n",
        "hybrid_lgbmsvm_recall = recall_score(y_test, hybrid_lgbmsvm_predictions)\n",
        "hybrid_lgbmsvm_f1 = f1_score(y_test, hybrid_lgbmsvm_predictions)\n",
        "hybrid_lgbmsvm_accuracy = accuracy_score(y_test, hybrid_lgbmsvm_predictions)\n",
        "hybrid_lgbmsvm_roc_auc = roc_auc_score(y_test, hybrid_lgbmsvm_predictions)\n",
        "\n",
        "# 📌 9. False Positive & False Negative Rate berechnen\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, hybrid_lgbmsvm_predictions).ravel()\n",
        "hybrid_lgbmsvm_fpr = fp / (fp + tn)\n",
        "hybrid_lgbmsvm_fnr = fn / (fn + tp)\n",
        "\n",
        "# 📌 10. Precision@100 berechnen\n",
        "hybrid_lgbmsvm_p_at_100 = precision_at_k(y_test.to_numpy(), hybrid_lgbmsvm_predictions, k=100)\n",
        "\n",
        "# 📌 11. Ergebnisse ausgeben\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): Precision = {hybrid_lgbmsvm_precision:.2f}, Recall = {hybrid_lgbmsvm_recall:.2f}\")\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): F1-Score = {hybrid_lgbmsvm_f1:.2f}, Accuracy = {hybrid_lgbmsvm_accuracy:.2f}\")\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): ROC-AUC = {hybrid_lgbmsvm_roc_auc:.2f}\")\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): False Positive Rate (FPR) = {hybrid_lgbmsvm_fpr:.2f}\")\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): False Negative Rate (FNR) = {hybrid_lgbmsvm_fnr:.2f}\")\n",
        "print(f\"✅ Hybrid (LightGBM + OCSVM): Precision@100 = {hybrid_lgbmsvm_p_at_100:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7-NF86W66V7",
        "outputId": "c45c3357-8a88-4410-98d7-17136c19b7a3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Training One-Class SVM...\n",
            "✅ One-Class SVM Training abgeschlossen!\n",
            "🔍 Training LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 58630, number of negative: 67343\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007056 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1164\n",
            "[LightGBM] [Info] Number of data points in the train set: 125973, number of used features: 17\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465417 -> initscore=-0.138552\n",
            "[LightGBM] [Info] Start training from score -0.138552\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "✅ LightGBM Training abgeschlossen!\n",
            "✅ Hybrid (LightGBM + OCSVM): Precision = 0.90, Recall = 0.80\n",
            "✅ Hybrid (LightGBM + OCSVM): F1-Score = 0.85, Accuracy = 0.83\n",
            "✅ Hybrid (LightGBM + OCSVM): ROC-AUC = 0.84\n",
            "✅ Hybrid (LightGBM + OCSVM): False Positive Rate (FPR) = 0.12\n",
            "✅ Hybrid (LightGBM + OCSVM): False Negative Rate (FNR) = 0.20\n",
            "✅ Hybrid (LightGBM + OCSVM): Precision@100 = 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ergebnisse"
      ],
      "metadata": {
        "id": "CpDXzgr55gEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelle ohne Tuning vergleichen"
      ],
      "metadata": {
        "id": "WpyKw2E9FDH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 📌 1. Ergebnisse als DataFrame speichern\n",
        "results = pd.DataFrame({\n",
        "    \"Modell\": [\n",
        "        \"Regelbasiert\", \"Random Forest\", \"XGBoost\", \"LightGBM\", \"CatBoost\",\n",
        "        \"Isolation Forest\", \"One-Class SVM\", \"Autoencoder\",\n",
        "        \"Hybrid (Regel + RF)\", \"Hybrid (XGBoost + Isolation Forest)\", \"Hybrid (LightGBM + OCSVM)\"\n",
        "    ],\n",
        "    \"Precision\": [\n",
        "        rule_precision, rf_precision, xgb_precision, lgbm_precision, catboost_precision,\n",
        "        iso_precision, ocsvm_precision, autoencoder_precision,\n",
        "        hybrid_rrf_precision, hybrid_xgbif_precision, hybrid_lgbmsvm_precision\n",
        "    ],\n",
        "    \"Recall\": [\n",
        "        rule_recall, rf_recall, xgb_recall, lgbm_recall, catboost_recall,\n",
        "        iso_recall, ocsvm_recall, autoencoder_recall,\n",
        "        hybrid_rrf_recall, hybrid_xgbif_recall, hybrid_lgbmsvm_recall\n",
        "    ],\n",
        "    \"F1-Score\": [\n",
        "        rule_f1, rf_f1, xgb_f1, lgbm_f1, catboost_f1,\n",
        "        iso_f1, ocsvm_f1, autoencoder_f1,\n",
        "        hybrid_rrf_f1, hybrid_xgbif_f1, hybrid_lgbmsvm_f1\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        rule_accuracy, rf_accuracy, xgb_accuracy, lgbm_accuracy, catboost_accuracy,\n",
        "        iso_accuracy, ocsvm_accuracy, autoencoder_accuracy,\n",
        "        hybrid_rrf_accuracy, hybrid_xgbif_accuracy, hybrid_lgbmsvm_accuracy\n",
        "    ],\n",
        "    \"ROC-AUC\": [\n",
        "        rule_roc_auc, rf_roc_auc, xgb_roc_auc, lgbm_roc_auc, catboost_roc_auc,\n",
        "        None, None, None,  # Isolation Forest & Autoencoder haben kein klassisches ROC-AUC\n",
        "        hybrid_rrf_roc_auc, hybrid_xgbif_roc_auc, hybrid_lgbmsvm_roc_auc\n",
        "    ],\n",
        "    \"False Positive Rate (FPR)\": [\n",
        "        rule_fpr, rf_fpr, xgb_fpr, lgbm_fpr, catboost_fpr,\n",
        "        iso_fpr, ocsvm_fpr, autoencoder_fpr,\n",
        "        hybrid_rrf_fpr, hybrid_xgbif_fpr, hybrid_lgbmsvm_fpr\n",
        "    ],\n",
        "    \"False Negative Rate (FNR)\": [\n",
        "        rule_fnr, rf_fnr, xgb_fnr, lgbm_fnr, catboost_fnr,\n",
        "        iso_fnr, ocsvm_fnr, autoencoder_fnr,\n",
        "        hybrid_rrf_fnr, hybrid_xgbif_fnr, hybrid_lgbmsvm_fnr\n",
        "    ],\n",
        "    \"Precision@100\": [\n",
        "        rule_p_at_100, rf_p_at_100, xgb_p_at_100, lgbm_p_at_100, catboost_p_at_100,\n",
        "        iso_p_at_100, ocsvm_p_at_100, autoencoder_p_at_100,\n",
        "        hybrid_rrf_p_at_100, hybrid_xgbif_p_at_100, hybrid_lgbmsvm_p_at_100\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 📌 2. Tabelle in Google Colab anzeigen\n",
        "from IPython.display import display\n",
        "display(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "gGfqcoyUFIYi",
        "outputId": "42ebd50a-ad41-4450-993e-9c9dd3d3c3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 Modell  Precision    Recall  F1-Score  \\\n",
              "0                          Regelbasiert   0.986499  0.603522  0.748888   \n",
              "1                         Random Forest   0.967030  0.607964  0.746567   \n",
              "2                               XGBoost   0.968892  0.662589  0.786987   \n",
              "3                              LightGBM   0.967197  0.629549  0.762673   \n",
              "4                              CatBoost   0.968875  0.662199  0.786706   \n",
              "5                      Isolation Forest   0.859679  0.316995  0.463194   \n",
              "6                         One-Class SVM   0.805408  0.318008  0.455978   \n",
              "7                           Autoencoder   0.654545  0.115016  0.195652   \n",
              "8                   Hybrid (Regel + RF)   0.967900  0.737785  0.837320   \n",
              "9   Hybrid (XGBoost + Isolation Forest)   0.927244  0.734902  0.819944   \n",
              "10            Hybrid (LightGBM + OCSVM)   0.897454  0.799268  0.845520   \n",
              "\n",
              "    Accuracy   ROC-AUC  False Positive Rate (FPR)  False Negative Rate (FNR)  \\\n",
              "0   0.769606  0.796303                   0.010915                   0.396478   \n",
              "1   0.765037  0.790286                   0.027392                   0.392036   \n",
              "2   0.795822  0.817238                   0.028112                   0.337411   \n",
              "3   0.776969  0.800667                   0.028215                   0.370451   \n",
              "4   0.795600  0.817043                   0.028112                   0.337801   \n",
              "5   0.581751       NaN                   0.068376                   0.683005   \n",
              "6   0.568045       NaN                   0.101534                   0.681992   \n",
              "7   0.461675       NaN                   0.080218                   0.884984   \n",
              "8   0.836808  0.852725                   0.032334                   0.262215   \n",
              "9   0.816270  0.829350                   0.076202                   0.265098   \n",
              "10  0.833747  0.839290                   0.120688                   0.200732   \n",
              "\n",
              "    Precision@100  \n",
              "0            0.99  \n",
              "1            0.98  \n",
              "2            0.95  \n",
              "3            0.94  \n",
              "4            0.95  \n",
              "5            0.92  \n",
              "6            0.85  \n",
              "7            0.66  \n",
              "8            0.95  \n",
              "9            0.91  \n",
              "10           0.91  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55e98c11-2644-4c44-93b1-7f6645b19a03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modell</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>ROC-AUC</th>\n",
              "      <th>False Positive Rate (FPR)</th>\n",
              "      <th>False Negative Rate (FNR)</th>\n",
              "      <th>Precision@100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Regelbasiert</td>\n",
              "      <td>0.986499</td>\n",
              "      <td>0.603522</td>\n",
              "      <td>0.748888</td>\n",
              "      <td>0.769606</td>\n",
              "      <td>0.796303</td>\n",
              "      <td>0.010915</td>\n",
              "      <td>0.396478</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.967030</td>\n",
              "      <td>0.607964</td>\n",
              "      <td>0.746567</td>\n",
              "      <td>0.765037</td>\n",
              "      <td>0.790286</td>\n",
              "      <td>0.027392</td>\n",
              "      <td>0.392036</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.968892</td>\n",
              "      <td>0.662589</td>\n",
              "      <td>0.786987</td>\n",
              "      <td>0.795822</td>\n",
              "      <td>0.817238</td>\n",
              "      <td>0.028112</td>\n",
              "      <td>0.337411</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.967197</td>\n",
              "      <td>0.629549</td>\n",
              "      <td>0.762673</td>\n",
              "      <td>0.776969</td>\n",
              "      <td>0.800667</td>\n",
              "      <td>0.028215</td>\n",
              "      <td>0.370451</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.968875</td>\n",
              "      <td>0.662199</td>\n",
              "      <td>0.786706</td>\n",
              "      <td>0.795600</td>\n",
              "      <td>0.817043</td>\n",
              "      <td>0.028112</td>\n",
              "      <td>0.337801</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Isolation Forest</td>\n",
              "      <td>0.859679</td>\n",
              "      <td>0.316995</td>\n",
              "      <td>0.463194</td>\n",
              "      <td>0.581751</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.068376</td>\n",
              "      <td>0.683005</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>One-Class SVM</td>\n",
              "      <td>0.805408</td>\n",
              "      <td>0.318008</td>\n",
              "      <td>0.455978</td>\n",
              "      <td>0.568045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.101534</td>\n",
              "      <td>0.681992</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Autoencoder</td>\n",
              "      <td>0.654545</td>\n",
              "      <td>0.115016</td>\n",
              "      <td>0.195652</td>\n",
              "      <td>0.461675</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.080218</td>\n",
              "      <td>0.884984</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Hybrid (Regel + RF)</td>\n",
              "      <td>0.967900</td>\n",
              "      <td>0.737785</td>\n",
              "      <td>0.837320</td>\n",
              "      <td>0.836808</td>\n",
              "      <td>0.852725</td>\n",
              "      <td>0.032334</td>\n",
              "      <td>0.262215</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hybrid (XGBoost + Isolation Forest)</td>\n",
              "      <td>0.927244</td>\n",
              "      <td>0.734902</td>\n",
              "      <td>0.819944</td>\n",
              "      <td>0.816270</td>\n",
              "      <td>0.829350</td>\n",
              "      <td>0.076202</td>\n",
              "      <td>0.265098</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hybrid (LightGBM + OCSVM)</td>\n",
              "      <td>0.897454</td>\n",
              "      <td>0.799268</td>\n",
              "      <td>0.845520</td>\n",
              "      <td>0.833747</td>\n",
              "      <td>0.839290</td>\n",
              "      <td>0.120688</td>\n",
              "      <td>0.200732</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55e98c11-2644-4c44-93b1-7f6645b19a03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-55e98c11-2644-4c44-93b1-7f6645b19a03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-55e98c11-2644-4c44-93b1-7f6645b19a03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-032acd06-d9f0-48cd-897f-504d02a0ae4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-032acd06-d9f0-48cd-897f-504d02a0ae4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-032acd06-d9f0-48cd-897f-504d02a0ae4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7461d7c5-9d11-4c3f-9f96-107ff418ad0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7461d7c5-9d11-4c3f-9f96-107ff418ad0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Modell\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Isolation Forest\",\n          \"Regelbasiert\",\n          \"Hybrid (XGBoost + Isolation Forest)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1008495714358668,\n        \"min\": 0.6545454545454545,\n        \"max\": 0.9864985352184436,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.8596787827557059,\n          0.9864985352184436,\n          0.9272441254547242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2156385957140699,\n        \"min\": 0.11501597444089456,\n        \"max\": 0.7992675134419076,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.31699524662978257,\n          0.6035221694069975,\n          0.7349022052520845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21030305100579955,\n        \"min\": 0.1956521739130435,\n        \"max\": 0.8455197428076828,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.4631938514090521,\n          0.7488880293947012,\n          0.819944357503043\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1278213783018079,\n        \"min\": 0.46167494677075943,\n        \"max\": 0.8368080198722498,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.5817512420156139,\n          0.7696061036195884,\n          0.8162704045422285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC-AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021806057228632693,\n        \"min\": 0.7902861127318217,\n        \"max\": 0.8527254654769467,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7902861127318217,\n          0.8527254654769467,\n          0.7963033563542042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"False Positive Rate (FPR)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03623076896124993,\n        \"min\": 0.010915456698589229,\n        \"max\": 0.1206878797240243,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.07620224487694367,\n          0.027391617753063535,\n          0.10153434249819791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"False Negative Rate (FNR)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21563859571406988,\n        \"min\": 0.20073248655809242,\n        \"max\": 0.8849840255591054,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.6830047533702174,\n          0.3964778305930024,\n          0.2650977947479155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision@100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09121403400793103,\n        \"min\": 0.66,\n        \"max\": 0.99,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.98,\n          0.85,\n          0.99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}